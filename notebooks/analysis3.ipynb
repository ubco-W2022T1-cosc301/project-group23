{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minju Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research question/interests\n",
    "\n",
    "My research question asks: Is there a relationship between personality traits and race?\n",
    "\n",
    "Previous research shows the relationship between personality traits among various cultures and ethnicity. Cultures and ethnicity influence socialization patterns, which shape some of the variances of personality (Triandis & Suh, 2002). However, limited research investigates the relationship between personality traits and race. Therefore, I would like to investigate the relationship between personality traits and race. I hypothesized that a particular race group would show higher scores on the big five personality traits (extraversion, neuroticism, agreeableness, conscientiousness, openness) than other race groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/raw/data.csv\", sep='\\t')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: EDA\n",
    "Looking at the shape and general trends in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns are not useful to me and I will remove these in Task 2: age, engnat, gender, hand, source, country.\n",
    "Examining the race column further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.race.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 race values; I will rename them using the codebook and categorize/ remove them if needed in Task 2.\n",
    "Examining personality traits columns further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.filter(regex='E').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 extraversion items; I will calculate a total score and create a column for extraversion in Task 2. According to the codebook, certain items are reverse scored; I will manage it in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.filter(regex='N').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 neuroticism items; I will calculate a total score and create a column for neuroticism in Task 2. According to the codebook, certain items are reverse scored; I will manage it in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.filter(regex='A').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 agreeableness items; I will calculate a total score and create a column for agreeableness in Task 2. According to the codebook, certain items are reverse scored; I will manage it in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.filter(regex='C').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 conscientiousness items; I will calculate a total score and create a column for conscientiousness in Task 2. According to the codebook, certain items are reverse scored; I will manage it in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.filter(regex='O').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 openness items; I will calculate a total score and create a column for openness in Task 2. According to the codebook, certain items are reverse scored; I will manage it in Task 2.\n",
    "\n",
    "I am interested in the relationship between race and personality traits, so I will do a few plots to get a visual idea of the trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.hist(column= \"E1\", by = \"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the distribution of one item of extraversion for all races. Some races seem to have a similar trend of increasing and then decreasing extraversion scores; however, it is hard to distinguish the difference. I will not be likely to use this plot to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_eda = df_raw[['race','E1','N2','A2','C1','O1']].copy()\n",
    "bargraph_eda = df_raw_eda.groupby('race').mean().plot.bar()\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the mean average for one item of each personality trait, separated by race. All races seem to have the highest score on agreeableness and the lowest score on extraversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='E1', y='N2', hue='race', scatter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the relationship between one item of neuroticism and extraversion for all races. Most races seem to have a weak positive relationship between neuroticism and extraversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='E1', y='A2', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of agreeableness and extraversion for all races.\n",
    "# Most races seem to have a weak positive relationship between agreeableness and extraversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='E1', y='C1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of conscientiousness and extraversion for all races.\n",
    "# The relationship between conscientiousness and extraversion varies among races; it would be interesting to take a closer look at this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='E1', y='O1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of openness and extraversion for all races.\n",
    "# Most races seem to have no relationship between openness and extraversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='N2', y='A2', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of agreeableness and neuroticism for all races.\n",
    "# All races seem to have a weak positive relationship between agreeableness and neuroticism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='N2', y='C1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of conscientiousness and neuroticism for all races.\n",
    "# All races seem to have a weak positive relationship between conscientiousness and neuroticism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='N2', y='O1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of openness and neuroticism for all races.\n",
    "# Most races seem to have no relationship between openness and neuroticism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='A2', y='C1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of conscientiousness and agreeableness for all races.\n",
    "# Most races seem to have a weak positive relationship between conscientiousness and agreeableness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='A2', y='O1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of openness and agreeableness for all races.\n",
    "# Most races seem to have no relationship between openness and agreeableness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_raw, x='C1', y='O1', hue='race', scatter=False)\n",
    "\n",
    "# This plot shows the relationship between one item of openness and conscientiousness for all races.\n",
    "# Most races seem to have a weak positive relationship between openness and conscientiousness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have a good idea of the trends in the data relevant to my research question. There seems to be no significant relationship between personality traits and race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Analysis Pipeline\n",
    "\n",
    "#### 1. Load Data (already done)\n",
    "#### 2. Clean Data\n",
    "\n",
    "Remove columns that are not relevant to my research question: age, engnat, gender, hand, source, country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_raw.copy().drop(['age', 'engnat', 'gender', 'hand', 'source', 'country'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data: None and NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df_new).values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(df_new).values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are neither None nor NaN values. Good!\n",
    "\n",
    "#### 3. Process Data\n",
    "According to the codebook, items were rated on a five-point scale where 1=Disagree, 3=Neutral, 5=Agree (0=missed). <br>\n",
    "Reverse score certain items: E2, E4, E6, E8, E10, N1, N3, N5, N6, N7, N8, N9, N10, A1, A3, A5, A7, C2, C4, C6, C8, O2, O4, O6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse Scored Items: E2, E4, E6, E8, E10, N1, N3, N5, N6, N7, N8, N9, N10, A1, A3, A5, A7, C2, C4, C6, C8, O2, O4, O6\n",
    "\n",
    "def reverseScoring(df, high, cols):\n",
    "    '''\n",
    "    Reverse scores on given column(s).\n",
    "    \n",
    "    Arguments:\n",
    "    df - the data frame\n",
    "    high - (int) the highest score available\n",
    "    cols - the column(s) to reverse\n",
    "    '''\n",
    "    df[cols] = high - df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = reverseScoring(df_new, 6, cols=['E2','E4','E6','E8','E10','N1','N3','N5','N6','N7','N8','N9','N10','A1','A3','A5','A7','C2','C4','C6','C8','O2','O4','O6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create factor total scores for big five personality traits: extroversion, neuroticism, agreeableness, conscientiousness, openness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['E_Total'] = df_new.loc[:, 'E1':'E10'].sum(axis=1)\n",
    "df_new['N_Total'] = df_new.loc[:, 'N1':'N10'].sum(axis=1)\n",
    "df_new['A_Total'] = df_new.loc[:, 'A1':'A10'].sum(axis=1)\n",
    "df_new['C_Total'] = df_new.loc[:, 'C1':'C10'].sum(axis=1)\n",
    "df_new['O_Total'] = df_new.loc[:, 'O1':'O10'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data contains 13 race values. According to the codebook, each code refers to:\n",
    "\n",
    "1 = Mixed Race <br>\n",
    "2 = Arctic (Siberian, Eskimo) <br>\n",
    "3 = Caucasian (European) <br>\n",
    "4 = Caucasian (Indian) <br>\n",
    "5 = Caucasian (Middle East) <br>\n",
    "6 = Caucasian (North African, Other) <br>\n",
    "7 = Indigenous Australian <br>\n",
    "8 = Native American <br>\n",
    "9 = North East Asian (Mongol, Tibetan, Korean, Japanese, etc.) <br>\n",
    "10 = Pacific (Polynesian, Micronesian, etc.) <br>\n",
    "11 = South East Asian (Chinese, Thai, Malay, Filipino, etc.) <br>\n",
    "12 = West African, Bushmen <br>\n",
    "13 = Other\n",
    "\n",
    "Remove 1 and 13 and categorize into 5 groups.\n",
    "\n",
    "0. American Indian or Alaska Native: 2,8\n",
    "1. Asian: 9,11\n",
    "2. Black or African American: 7,12\n",
    "3. Native Hawaiian or Other Pacific Islander: 10\n",
    "4. White: 3,4,5,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['race'] != 1]\n",
    "df_new = df_new[df_new['race'] != 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.replace({'race':8},100)\n",
    "df_new = df_new.replace({'race':9},101)\n",
    "df_new = df_new.replace({'race':11},101)\n",
    "df_new = df_new.replace({'race':7},102)\n",
    "df_new = df_new.replace({'race':12},102)\n",
    "df_new = df_new.replace({'race':10},103)\n",
    "df_new = df_new.replace({'race':3},104)\n",
    "df_new = df_new.replace({'race':4},104)\n",
    "df_new = df_new.replace({'race':5},104)\n",
    "df_new = df_new.replace({'race':6},104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.replace({'race':100},0)\n",
    "df_new = df_new.replace({'race':101},1)\n",
    "df_new = df_new.replace({'race':102},2)\n",
    "df_new = df_new.replace({'race':103},3)\n",
    "df_new = df_new.replace({'race':104},4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Wrangle Data\n",
    "Create a data frame that only contains relevant to my research question:\n",
    "- Categorized race: American Indian or Alaska Native, Asian, Black or African American, Native Hawaiian or Other Pacific Islander, White.\n",
    "- Factor total scores for the big five personality traits: Extroversion, Neuroticism, Agreeableness, Conscientiousness, Openness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_new[['race', 'E_Total', 'N_Total', 'A_Total', 'C_Total', 'O_Total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for the big five personality traits and race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.rename(columns={'E_Total':'Extraversion',\n",
    "                                       'N_Total':'Neuroticism',\n",
    "                                       'A_Total':'Agreeableness',\n",
    "                                       'C_Total':'Conscientiousness',\n",
    "                                       'O_Total':'Openness',\n",
    "                                       'race':'Race'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.replace({'Race':0}, 'American Indian or Alaska Native')\n",
    "df_cleaned = df_cleaned.replace({'Race':1}, 'Asian')\n",
    "df_cleaned = df_cleaned.replace({'Race':2}, 'Black or African American')\n",
    "df_cleaned = df_cleaned.replace({'Race':3}, 'Native Hawaiian or Other Pacific Islander')\n",
    "df_cleaned = df_cleaned.replace({'Race':4}, 'White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. EDA (Visualization)\n",
    "Bar plot showing the comparison of mean factor scores of the big five personality traits, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bargraph = df_cleaned.groupby('Race').mean().plot.bar(grid=True, width=.5, alpha=.90)\n",
    "mean_bargraph.set(xlabel=None)\n",
    "plt.xticks(rotation=70)\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0), fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot showing the comparison of median factor scores of the big five personality traits, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bargraph = df_cleaned.groupby('Race').median().plot.bar(grid=True, width=.5, alpha=.90)\n",
    "median_bargraph.set(xlabel=None)\n",
    "plt.xticks(rotation=70)\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0), fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for American Indian or Alaska Native:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_american = df_cleaned[df_cleaned['Race'] == 'American Indian or Alaska Native']\n",
    "df_corr_american = df_cleaned_american.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_american, ax=ax, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('American Indian or Alaska Native')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Asian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_asian = df_cleaned[df_cleaned['Race'] == 'Asian']\n",
    "df_corr_asian = df_cleaned_asian.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_asian, ax=ax, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Asian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Black or African American:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_black = df_cleaned[df_cleaned['Race'] == 'Black or African American']\n",
    "df_corr_black = df_cleaned_black.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_black, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Black or African American')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Native Hawaiian or Other Pacific Islander:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_native = df_cleaned[df_cleaned['Race'] == 'Native Hawaiian or Other Pacific Islander']\n",
    "df_corr_native = df_cleaned_native.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_native, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Native Hawaiian or Other Pacific Islander')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for White:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_white = df_cleaned[df_cleaned['Race'] == 'White']\n",
    "df_corr_white = df_cleaned_white.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_white, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('White')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Neuroticism, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Neuroticism', hue='Race',  scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Agreeableness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Agreeableness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Agreeableness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Agreeableness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Agreeableness and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Agreeableness', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Agreeableness and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Agreeableness', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Conscientiousness and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Conscientiousness', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Method Chaining and writing Python programs\n",
    "Step 1: Build and test the method chain(s). <br>\n",
    "Transfer the steps to load, clean, process, and wrangle the data in Task 2 into a .py file.\n",
    "#### Load package(s) and function(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import project_functions3 as pf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Chain 1:\n",
    "Method chain to load a .csv file and drop unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = (pd.read_csv(\"../data/raw/data.csv\", sep='\\t')\n",
    "        .copy().drop(['age', 'engnat', 'gender', 'hand', 'source', 'country'], axis=1))\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Chain 2:\n",
    "Method chain to reverse score items that are reverse-coded and assign new columns containing factor total scores by summing scores on the constituent items for each factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseScoring(df, high, cols):\n",
    "    '''\n",
    "    Reverse scores on given column(s).\n",
    "    \n",
    "    Arguments:\n",
    "    df - the data frame\n",
    "    high - (int) the highest score available\n",
    "    cols - the column(s) to reverse\n",
    "    '''\n",
    "    df[cols] = high - df[cols]\n",
    "    return df\n",
    "\n",
    "df_1 = reverseScoring(df_1, 6, cols=['E2','E4','E6','E8','E10','N1','N3','N5','N6','N7','N8','N9','N10','A1','A3','A5','A7','C2','C4','C6','C8','O2','O4','O6'])\n",
    "\n",
    "df_2 = (pd.DataFrame(df_1)\n",
    "        .assign(E_Total=lambda x: df_1.loc[:, 'E1':'E10'].sum(axis=1))\n",
    "        .assign(N_Total=lambda x: df_1.loc[:, 'N1':'N10'].sum(axis=1))\n",
    "        .assign(A_Total=lambda x: df_1.loc[:, 'A1':'A10'].sum(axis=1))\n",
    "        .assign(C_Total=lambda x: df_1.loc[:, 'C1':'C10'].sum(axis=1))\n",
    "        .assign(O_Total=lambda x: df_1.loc[:, 'O1':'O10'].sum(axis=1)))\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Wrap the method chain(s) in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_functions3 as pf3\n",
    "df = pf3.load_and_process(\"../data/raw/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice and clean!\n",
    "## Task 4: Analysis for the Research Question(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_functions3 as pf3\n",
    "df = pf3.load_and_process(\"../data/raw/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['race'] != 1]\n",
    "df = df[df['race'] != 13]\n",
    "\n",
    "df = df.replace({'race':8},'American Indian or Alaska Native')\n",
    "df = df.replace({'race':9},'Asian')\n",
    "df = df.replace({'race':11},'Asian')\n",
    "df = df.replace({'race':7},'Black or African American')\n",
    "df = df.replace({'race':12},'Black or African American')\n",
    "df = df.replace({'race':10},'Native Hawaiian or Other Pacific Islander')\n",
    "df = df.replace({'race':3},'White')\n",
    "df = df.replace({'race':4},'White')\n",
    "df = df.replace({'race':5},'White')\n",
    "df = df.replace({'race':6},'White')\n",
    "\n",
    "df_cleaned = df[['race', 'E_Total', 'N_Total', 'A_Total', 'C_Total', 'O_Total']]\n",
    "df_cleaned = df_cleaned.rename(columns={'E_Total':'Extraversion',\n",
    "                                       'N_Total':'Neuroticism',\n",
    "                                       'A_Total':'Agreeableness',\n",
    "                                       'C_Total':'Conscientiousness',\n",
    "                                       'O_Total':'Openness',\n",
    "                                       'race':'Race'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My research question asks: Is there a relationship between personality traits and race?\n",
    "Bar plot showing the comparison of mean factor scores of the big five personality traits, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bargraph = df_cleaned.groupby('Race').mean().plot.bar(grid=True, width=.5, alpha=.90)\n",
    "mean_bargraph.set(xlabel=None)\n",
    "plt.xticks(rotation=70)\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0), fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot showing the comparison of median factor scores of the big five personality traits, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bargraph = df_cleaned.groupby('Race').median().plot.bar(grid=True, width=.5, alpha=.90)\n",
    "median_bargraph.set(xlabel=None)\n",
    "plt.xticks(rotation=70)\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0), fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for American Indian or Alaska Native:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_american = df_cleaned[df_cleaned['Race'] == 'American Indian or Alaska Native']\n",
    "df_corr_american = df_cleaned_american.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_american, ax=ax, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('American Indian or Alaska Native')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Asian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_asian = df_cleaned[df_cleaned['Race'] == 'Asian']\n",
    "df_corr_asian = df_cleaned_asian.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_asian, ax=ax, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Asian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Black or African American:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_black = df_cleaned[df_cleaned['Race'] == 'Black or African American']\n",
    "df_corr_black = df_cleaned_black.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_black, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Black or African American')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for Native Hawaiian or Other Pacific Islander:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_native = df_cleaned[df_cleaned['Race'] == 'Native Hawaiian or Other Pacific Islander']\n",
    "df_corr_native = df_cleaned_native.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_native, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('Native Hawaiian or Other Pacific Islander')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of the big five personality traits for White:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_white = df_cleaned[df_cleaned['Race'] == 'White']\n",
    "df_corr_white = df_cleaned_white.corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(df_corr_white, annot=True, cbar_kws={'label':'Correlation Coefficient'})\n",
    "ax.set_title('White')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Neuroticism, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Neuroticism', hue='Race',  scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Agreeableness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Agreeableness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Extraversion and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Extraversion', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Agreeableness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Agreeableness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Neuroticism and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Neuroticism', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Agreeableness and Conscientiousness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Agreeableness', y='Conscientiousness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Agreeableness and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Agreeableness', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the relationship between Conscientiousness and Openness, by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(df_cleaned, x='Conscientiousness', y='Openness', hue='Race', scatter=False, legend=False)\n",
    "plt.legend(fontsize='8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
